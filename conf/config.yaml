training:
  max_epochs: 20
  batch_size: 256
  peak_learning_rate: 3e-4
  warmup_steps: 2000
  total_steps: 163000
  end_learning_rate: 3e-5
  weight_decay: 0.1
  gradient_accumulation_steps: 4
  evaluation_frequency: 1000 
  maximum_evaluation_steps: 250
  train_context: 1024
  dp: 4
  mp: 8

model:
  size: "760m"



data:
  corpus: "pile_codeparrot_mix"
  max_context: 2048
  train_samples: 14809244
  checkpoint_directory: "checkpoints"
  bucket_path: "bfattoripile_euwest"
  index_path_train: "data/index/pileeu_train_code_mix.index"
  index_path_validation: "data/index/pileeu_validation.index"
  wandb_project: "jax-transformer"
  steps_per_epoch: 30800 # approximation 