training:
  batch_size: 16
  peak_learning_rate: 8e-4
  warmup_steps: 500
  decay_steps: 2000
  total_steps: 2500
  end_learning_rate: 6e-5
  weight_decay: 0.1
  gradient_accumulation_steps: 64
  evaluation_frequency: 500
  maximum_evaluation_steps: 500
  precision: 'bf16'

model:
  size: "small"

data:
  corpus: "bookcorpus2"
  train_shard_urls: "data/processed/books_train-{000000..000013}.tar.gz"
  validation_shard_urls: "data/processed/bookcorpus_val-{000000..000002}.tar.gz"
  max_context: 1024
  workers: 1
  checkpoint_directory: "checkpoints"