training:
  max_epochs: 20
  batch_size: 32
  peak_learning_rate: 6.0e-4
  warmup_steps: 2000
  decay_steps: 230000
  total_steps: 210000
  end_learning_rate: 6.0e-5
  weight_decay: 0.1
  gradient_accumulation_steps: 4
  evaluation_frequency: 1000
  maximum_evaluation_steps: 500
  precision: 'fp32'
  staged_warmup_steps: 1000001
  warmup_train_context: 2048

model:
  size: "bytelevelbase"
  warm_start: False
  model_path: "warmstart_params/warmstart_params_XXL.msgpack"

data:
  corpus: "openwebtext"
  train_shard_urls:
  validation_shard_urls: 
  max_context: 4096
  train_samples: 14809244
  checkpoint_directory: "checkpoints"
  bucket_path: "bfattoriwebtext2"
  index_path_train: "data/index/openwebtext2_train.index"
  index_path_validation: "data/index/openwebtext2_validation.index"
  wandb_project: "jax-transformer"
  resume_step: 40000

device: 
  dp_devices: 32
  mp_devices: 1