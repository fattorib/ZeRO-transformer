training:
  max_epochs: 20
  batch_size: 256
  peak_learning_rate: 1e-4
  warmup_steps: 1000
  total_steps: 25000
  end_learning_rate: 1e-5
  weight_decay: 0.1
  gradient_accumulation_steps: 4
  evaluation_frequency: 1000 
  maximum_evaluation_steps: 250
  train_context: 2048

model:
  size: "417m"
  warm_init: True
  warm_init_dir: "warm_initialization"


data:
  corpus: "pile_codeparrot_mix"
  max_context: 2048
  train_samples: 14809244
  checkpoint_directory: "checkpoints"
  bucket_path: "bfattoripile_euwest"
  index_path_train: "data/index/code_train.index"
  index_path_validation: "data/index/pileeu_validation.index"
  wandb_project: "jax-transformer"
  steps_per_epoch: 3800 # approximation 