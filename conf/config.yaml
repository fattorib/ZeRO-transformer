training:
  batch_size: 16
  peak_learning_rate: 8e-4
  warmup_steps: 500
  decay_steps: 2000
  total_steps: 2500
  end_learning_rate: 8e-5
  weight_decay: 0.1
  gradient_accumulation_steps: 32
  evaluation_frequency: 500
  maximum_evaluation_steps: 500
  precision: 'bf16'
  staged_sequences: [256,512]
  staged_warmup_steps: 1000

model:
  size: "small"

distillation:
  distill: True
  temperature: 2
  alpha: 0.5

data:
  corpus: "bookcorpus2"
  train_shard_urls: "data/processed/books_train-{000000..000013}.tar.gz"
  validation_shard_urls: "data/processed/bookcorpus_val-{000000..000002}.tar.gz"
  max_context: 1024
  workers: 1
  checkpoint_directory: "checkpoints"