training:
  max_epochs: 20
  batch_size: 256
  peak_learning_rate: 1.6e-5
  warmup_steps: 2000
  total_steps: 120000
  end_learning_rate: 1.6e-6
  weight_decay: 1.0
  gradient_accumulation_steps: 128
  evaluation_frequency: 1000 
  maximum_evaluation_steps: 125
  train_context: 1024
  dp: 4
  mp: 8

model:
  size: "2_7b"


data:
  corpus: "pile_codeparrot_mix"
  max_context: 2048
  train_samples: 14809244
  checkpoint_directory: "checkpoints"
  bucket_path: "bfattoripile_euwest"
  index_path_train: "data/index/pileeu_train_code_mix.index"
  index_path_validation: "data/index/pileeu_validation.index"
  wandb_project: "jax-transformer-tp"
  steps_per_epoch: 30800 # approximation 